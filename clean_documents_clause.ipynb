{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# sets the output directory\n",
    "cba_path = os.path.join(\".\", \"cleaned_cba_samples_small\")\n",
    "if not os.path.isdir(cba_path):\n",
    "    os.mkdir(cba_path)\n",
    "\n",
    "# sets the input directory\n",
    "file_path = os.getcwd() + '/cba_samples_small'\n",
    "# file_path = '/Users/calvineng/Dropbox/Calvin_Eng/cba_text_analysis/cba_txt_2009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cl_ace_ate_med', 'cl_ace_inf_emp', 'cl_ace_sin_loc_tra', 'cl_aco_aci_por_doe_pro', 'cl_ada_fun', 'cl_adi_hor_ext', 'cl_adi_ins', 'cl_adi_not', 'cl_adi_pen_tur', 'cl_adi_per', 'cl_adi_sob', 'cl_adi_tem_ser', 'cl_aju_cus', 'cl_apl_ins_col', 'cl_apo', 'cl_ass_mor', 'cl_ass_sex', 'cl_atr_fun_des_fun', 'cl_aut_tra_nos_dom_fer', 'cl_aux_ali', 'cl_aux_cre', 'cl_aux_doe_inv', 'cl_aux_edu', 'cl_aux_hab', 'cl_aux_mat', 'cl_aux_mor_fun', 'cl_aux_sau', 'cl_aux_tra', 'cl_ava_des', 'cl_avi_pre', 'cl_cam_edu_sob_sau', 'cl_cip_com_ele_atr_gar_aos_cip', 'cl_com', 'cl_com_fab', 'cl_com_jor', 'cl_con_amb_tra', 'cl_con_jor', 'cl_con_sin', 'cl_con_tem_par', 'cl_dec_ter_sal', 'cl_des_dem', 'cl_des_ins_col', 'cl_des_sal', 'cl_des_sem', 'cl_dir_opo_des_con_sin', 'cl_dur_con_fer', 'cl_dur_hor', 'cl_emp', 'cl_equ_pro_ind', 'cl_equ_seg', 'cl_est_abo', 'cl_est_aci_por_doe_pro', 'cl_est_ado', 'cl_est_apo', 'cl_est_apr', 'cl_est_ger', 'cl_est_mae', 'cl_est_pai', 'cl_est_por_doe_nao_pro', 'cl_est_ser_mil', 'cl_exa_med', 'cl_fal', 'cl_fer_col', 'cl_fer_equ_tra', 'cl_gar_dir_sin', 'cl_gar_por_doe_nao_pro', 'cl_gio_apr', 'cl_gra_fun', 'cl_igu_opo', 'cl_ins', 'cl_int_par_des', 'cl_iso_sal', 'cl_jor_esp_mul_men_est', 'cl_lib_emp_par_ati_sin', 'cl_lic_abo', 'cl_lic_ado', 'cl_lic_mat', 'cl_lic_nao_rem', 'cl_lic_rem', 'cl_man_maq_equ', 'cl_mao_obr_fai_eta_ava', 'cl_mao_obr_fem', 'cl_mao_obr_jov', 'cl_mao_obr_tem_ter', 'cl_mec_sol_con', 'cl_nor_dis', 'cl_nor_par_adm_con', 'cl_out_adi', 'cl_out_aux', 'cl_out_dis', 'cl_out_dis_sob_fer_lic', 'cl_out_dis_sob_jor', 'cl_out_dis_sob_rel_ent_sin_emp', 'cl_out_dis_sob_rep_org', 'cl_out_est', 'cl_out_gra', 'cl_out_gru_esp', 'cl_out_nor_pes', 'cl_out_nor_pre_aci_doe_pro', 'cl_out_nor_pro_aci_doe', 'cl_out_nor_ref_adm_dem_mod_con', 'cl_out_nor_ref_con_par_exe_tra', 'cl_out_nor_ref_sal_rea_pag_cri_p', 'cl_pag_sal_for_pra', 'cl_par_dos_tra_ges_das_emp', 'cl_par_nos_luc_res', 'cl_per', 'cl_pis_sal', 'cl_pla_car_sal', 'cl_pol_man_emp', 'cl_pol_par_dep', 'cl_por_nec_esp', 'cl_pre', 'cl_pri_soc', 'cl_pro_pro_emp_ppe_lei_13_201', 'cl_pro_red_jor', 'cl_pro_rel_gre_gre', 'cl_pro_sau_seg', 'cl_qua_for_pro', 'cl_rea_aci_por_doe_pro', 'cl_rea_cor_sal', 'cl_reg_par_neg', 'cl_rem_dsr', 'cl_rem_fer', 'cl_ren_res_ins_col', 'cl_rep_sin', 'cl_sal_fam', 'cl_sal_gio_men_apr', 'cl_sal_pro_tar', 'cl_seg_vid', 'cl_sin_cam_con_sin', 'cl_sob', 'cl_sus_con_tra', 'cl_tra_set_emp', 'cl_tre_par_pre_aci_doe_tra', 'cl_tur_ini_rev', 'cl_uni']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# theme and translation dictionaries for clause_groups\n",
    "clause_groups = pd.read_csv('clause_groups.csv', index_col='name_pt')\n",
    "varname_dict = clause_groups['varname'].to_dict()\n",
    "varnames = list(map(str, clause_groups['varname'].unique()))\n",
    "\n",
    "#  prints for confirmation\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import dropwhile, takewhile\n",
    "import io\n",
    "import re\n",
    "\n",
    "# retrieves the type of document\n",
    "def extract_document_type(file_path):\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        lines = (line.strip() for line in f)   \n",
    "        title_start_flage = dropwhile(lambda line: '<STARTofTITLE>' not in line, lines)\n",
    "        next(title_start_flage,\"\")\n",
    "        title_end_flag = takewhile(lambda line: '<ENDofTITLE>' not in line, title_start_flage)\n",
    "        title = ''.join(title_end_flag).strip()\n",
    "        if 'Extrato Acordo Coletivo' in title:\n",
    "            acordo, extrato = 1, 1\n",
    "        elif 'Extrato Convenção Coletiva' in title:\n",
    "            acordo, extrato = 0, 1\n",
    "        elif 'Extrato Termo Aditivo de Acordo Coletivo' in title:\n",
    "            acordo, extrato = 1, 0\n",
    "        elif 'Extrato Termo Aditivo de Convenção Coletiva' in title:\n",
    "            acordo, extrato = 0, 0\n",
    "        else:\n",
    "            acordo, extrato = '', ''\n",
    "\n",
    "    return acordo, extrato\n",
    "\n",
    "# retrieves the validity\n",
    "def extract_validity(file_path):\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        lines = (line.strip() for line in f) \n",
    "        validity_start_flag = dropwhile(lambda line: '<STARTofVALIDITY>' not in line, lines)\n",
    "        next(validity_start_flag,\"\")\n",
    "        validity_end_flag = takewhile(lambda line: '<ENDofVALIDITY>' not in line, validity_start_flag)\n",
    "        validity = ''.join(validity_end_flag).strip()\n",
    "        if 'carimbo' in validity:\n",
    "            validity = 1\n",
    "        elif 'semvalorlegal' in validity:\n",
    "            validity = 0\n",
    "        else:\n",
    "            validity = ''\n",
    "\n",
    "    return validity\n",
    "\n",
    "# extracts the types of clauses present\n",
    "def extract_clause_names(file_path):\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        varnames = []\n",
    "        lines = (line.strip() for line in f)      \n",
    "        clause_flag_start = dropwhile(lambda line: '<STARTofCLAUSES>' not in line, lines)\n",
    "        next(clause_flag_start,\"\")\n",
    "        clause_flag_end = takewhile(lambda line: '<ENDofCLAUSES>' not in line, clause_flag_start)\n",
    "        for line in clause_flag_end:\n",
    "            if not line: \n",
    "                continue\n",
    "            try: \n",
    "                title = line.split('|')[0]\n",
    "                varname = varname_dict[title]\n",
    "            except:\n",
    "                varname = ''\n",
    "            varnames.append(varname)\n",
    "\n",
    "    return varnames\n",
    "\n",
    "# extracts the text of clauses\n",
    "def extract_clause_texts(file_path):\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        text = []\n",
    "        texts = []\n",
    "        lines = (line.strip() for line in f)  \n",
    "        text_flag_start = dropwhile(lambda line: '<STARTofTEXT>' not in line, lines)\n",
    "        next(text_flag_start, \"\")\n",
    "        for line in text_flag_start:\n",
    "            if not line:\n",
    "                continue\n",
    "            elif '|' in line: \n",
    "                text.append(line.split('|')[0])\n",
    "                texts.append((' ').join(text).strip())\n",
    "                text = [line.split('|')[1]]\n",
    "            else:\n",
    "                text.append(line)\n",
    "        if text:\n",
    "            texts.append((' ').join(text).strip())\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleans each cluase in a document\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\xa0',' ')\n",
    "    phrases = ['PARÁGRAFO ÚNICO', 'PARÁGRAFO PRIMEIRO', 'PARÁGRAFO SEGUNDO', 'PARÁGRAFO TERCEIRO', \n",
    "        'PARÁGRAFO QUARTO', 'PARÁGRAFO QUINTO', 'PARÁGRAFO SEXTO', 'PARÁGRAFO SÉTIMO',\n",
    "        'PARÁGRAFO OITAVO', 'PARÁGRAFO NONO', 'PARÁGRAFO DÉCIMO']\n",
    "    pattern = '|'.join(fr\"{phrase}\\s?[:–-]\\s?\" for phrase in phrases)\n",
    "    text = re.sub(pattern, ' ', text, flags=re.IGNORECASE)\n",
    "    text = text.replace('|',' ')\n",
    "    text = text.replace('R$', ' ')\n",
    "    text = text.replace('%', ' ')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace('\"', ' ')\n",
    "    text = text.replace('“', ' ')\n",
    "    text = text.replace('”', ' ')\n",
    "    text = text.replace('·', ' ')\n",
    "    text = re.sub(r'CEEE D', 'CEEE-D', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\.\\s[–-]|\\.\\s?[–-]', '. ', text) # '. –', '. -', '.–', '.-'\n",
    "    text = re.sub(r'\\(.*?\\)', ' ', text) # (...)\n",
    "    text = re.sub(r'[A-Z]\\) [–-]', ' ', text, flags=re.IGNORECASE) # A) -\n",
    "    text = re.sub(r'[A-Z]\\)[–-]', ' ', text, flags=re.IGNORECASE) # A)-\n",
    "    text = re.sub(r'[A-Z]\\)', ' ', text, flags=re.IGNORECASE) # A)\n",
    "    text = re.sub(r'[A-Z]\\.\\d+\\)', ' ', text, flags=re.IGNORECASE) # a.1)\n",
    "    text = re.sub(r'§ \\d+º [–-]', ' ', text) # § 1º -\n",
    "    text = text.replace('§', ' ')\n",
    "    text = re.sub(r'parágrafo\\s*?\\d+[°º]\\s*?[–-]', ' ', text, flags=re.IGNORECASE) # Parágrafo 2° - \n",
    "    text = re.sub(r'\\d+[°º]\\s*?trimestre\\s*?[–-]', ' ', text, flags=re.IGNORECASE) # 1º trimestre –\n",
    "    text = re.sub(r'\\s+([.,:;?!])', r'\\1', text) # spaces before punctuation\n",
    "    text = re.sub('\\s{2,}', ' ', text) # unessecary white spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def output_all(file_path_x, files_x):\n",
    "    # contract identifier\n",
    "    contract_id = files_x[:-4]\n",
    "\n",
    "    # extracts information from document\n",
    "    file_path = os.path.join(file_path_x, files_x)\n",
    "    acordo, extrato = extract_document_type(file_path)\n",
    "    validity = extract_validity(file_path)\n",
    "\n",
    "    if acordo == 1 and extrato == 1 and validity == 1:\n",
    "        varnames = extract_clause_names(file_path)\n",
    "        texts = extract_clause_texts(file_path)\n",
    "        cleaned_texts = map(clean_text, texts)\n",
    "        clauses_dict = [(varname, text) for varname, text in zip(varnames, cleaned_texts)]\n",
    "        file_destination = os.path.join(cba_path, contract_id + '_cleaned.txt')\n",
    "        with open(file_destination, 'w', encoding='utf8') as f:\n",
    "            json.dump(clauses_dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 507.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for file in tqdm(os.listdir(file_path)):\n",
    "    if file == '.DS_Store' or file == 'Desktop.ini':\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        output_all(file_path, file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {file}\")\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
